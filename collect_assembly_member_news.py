#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒì˜ì› êµ­ì •ê°ì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
- ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ì‚¬ìš©
- ê° êµ­íšŒì˜ì›ë³„ë¡œ "ì´ë¦„ + êµ­ì •ê°ì‚¬" í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
- ë§¤ì¼ 50ê±´ì”© 3íšŒ ìˆ˜ì§‘ (ì´ 150ê±´/ì¼)
"""

import requests
import json
import time
from datetime import datetime, timedelta
import os
import schedule

# ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
CLIENT_ID = "kXwlSsFmb055ku9rWyx1"
CLIENT_SECRET = "JZqw_LTiq_"

# API ì—”ë“œí¬ì¸íŠ¸
NAVER_NEWS_API_URL = "https://openapi.naver.com/v1/search/news.json"

# ë°ì´í„° ì €ì¥ ê²½ë¡œ
OUTPUT_DIR = "news_data"
ASSEMBLY_DATA_FILE = "assembly_by_region.json"  # ì „êµ­ 298ëª… ë°ì´í„°
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "assembly_member_news.json")


def load_assembly_members():
    """êµ­íšŒì˜ì› ëª…ë‹¨ ë¡œë“œ (ì „êµ­ 298ëª…)"""
    print("ğŸ“‚ êµ­íšŒì˜ì› ë°ì´í„° ë¡œë”© ì¤‘...")
    
    if not os.path.exists(ASSEMBLY_DATA_FILE):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ASSEMBLY_DATA_FILE}")
        return []
    
    with open(ASSEMBLY_DATA_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    members = []
    
    # ì§€ì—­êµ¬ ì˜ì›
    if 'regional' in data:
        for sido, member_list in data['regional'].items():
            for member_data in member_list:
                name = member_data.get('name', '')
                party = member_data.get('party', '')
                district = member_data.get('district', '')
                
                if name:
                    members.append({
                        'name': name,
                        'district': district,
                        'party': party
                    })
    
    # ë¹„ë¡€ëŒ€í‘œ ì˜ì›
    if 'proportional' in data:
        for party, member_list in data['proportional'].items():
            for member_data in member_list:
                name = member_data.get('name', '')
                
                if name:
                    members.append({
                        'name': name,
                        'district': 'ë¹„ë¡€ëŒ€í‘œ',
                        'party': party
                    })
    
    print(f"âœ… {len(members)}ëª…ì˜ êµ­íšŒì˜ì› ë¡œë“œ ì™„ë£Œ")
    return members


def search_naver_news(query, display=50, start=1, retry_count=3):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET
    }
    
    params = {
        "query": query,
        "display": display,
        "start": start,
        "sort": "date"  # ìµœì‹ ìˆœ ì •ë ¬
    }
    
    for attempt in range(retry_count):
        try:
            response = requests.get(NAVER_NEWS_API_URL, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.Timeout:
            print(f"  âš ï¸  íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{retry_count})")
            if attempt < retry_count - 1:
                time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
        except requests.exceptions.ConnectionError:
            print(f"  âš ï¸  ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{retry_count})")
            if attempt < retry_count - 1:
                time.sleep(5)  # 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
        except requests.exceptions.HTTPError as e:
            print(f"  âŒ HTTP ì˜¤ë¥˜: {e.response.status_code}")
            if e.response.status_code == 429:  # Too Many Requests
                print(f"  â³ API í˜¸ì¶œ í•œë„ ì´ˆê³¼, 60ì´ˆ ëŒ€ê¸°...")
                time.sleep(60)
            break  # HTTP ì—ëŸ¬ëŠ” ì¬ì‹œë„ ì•ˆí•¨
        except requests.exceptions.RequestException as e:
            print(f"  âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}")
            break
    
    return None


def collect_member_news(member, max_articles=50):
    """íŠ¹ì • êµ­íšŒì˜ì›ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    name = member['name']
    query = f"{name} êµ­ì •ê°ì‚¬"
    
    print(f"ğŸ” ê²€ìƒ‰ ì¤‘: {query}")
    
    result = search_naver_news(query, display=max_articles)
    
    if not result or 'items' not in result:
        print(f"  âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return []
    
    articles = []
    for item in result['items']:
        article = {
            'title': item['title'].replace('<b>', '').replace('</b>', ''),
            'description': item.get('description', '').replace('<b>', '').replace('</b>', ''),
            'link': item['link'],
            'pubDate': item['pubDate'],
            'originallink': item.get('originallink', '')
        }
        articles.append(article)
    
    print(f"  âœ… {len(articles)}ê±´ ìˆ˜ì§‘")
    return articles


def load_existing_data():
    """ê¸°ì¡´ ìˆ˜ì§‘ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_data(data):
    """ë°ì´í„° ì €ì¥"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {OUTPUT_FILE}")


def check_internet_connection():
    """ì¸í„°ë„· ì—°ê²° í™•ì¸"""
    try:
        response = requests.get("https://www.google.com", timeout=5)
        return True
    except:
        return False


def collect_all_news():
    """ëª¨ë“  êµ­íšŒì˜ì›ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ (1íšŒ ì‹¤í–‰)"""
    print("\n" + "="*60)
    print(f"ğŸ• ìˆ˜ì§‘ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60 + "\n")
    
    # ì¸í„°ë„· ì—°ê²° í™•ì¸
    if not check_internet_connection():
        print("âŒ ì¸í„°ë„· ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
        print("ğŸ“ ë‹¤ìŒ ìˆ˜ì§‘ ì˜ˆì • ì‹œê°„ì— ìë™ìœ¼ë¡œ ì¬ì‹œë„ë©ë‹ˆë‹¤.")
        
        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists(OUTPUT_FILE):
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            print(f"âœ… ê¸°ì¡´ ë°ì´í„° ìœ ì§€: {len(existing_data)}ëª…, {sum(d['total_count'] for d in existing_data.values())}ê±´")
        else:
            print("âš ï¸  ê¸°ì¡´ ë°ì´í„°ë„ ì—†ìŠµë‹ˆë‹¤. ì˜¨ë¼ì¸ ìƒíƒœì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        return
    
    print("âœ… ì¸í„°ë„· ì—°ê²° í™•ì¸ ì™„ë£Œ\n")
    
    members = load_assembly_members()
    if not members:
        print("âŒ êµ­íšŒì˜ì› ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    all_data = load_existing_data()
    
    # ê° êµ­íšŒì˜ì›ë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
    collected_count = 0
    failed_count = 0
    
    for i, member in enumerate(members, 1):
        name = member['name']
        
        print(f"\n[{i}/{len(members)}] {name} ({member['district']}, {member['party']})")
        
        # ë‰´ìŠ¤ ìˆ˜ì§‘ (50ê±´)
        articles = collect_member_news(member, max_articles=50)
        
        if articles:
            # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            if name not in all_data:
                all_data[name] = {
                    'member_info': member,
                    'collected_date': datetime.now().strftime('%Y%m%d'),
                    'total_count': 0,
                    'news': []
                }
            
            # ì¤‘ë³µ ì²´í¬ (ë§í¬ ê¸°ì¤€)
            existing_links = {article['link'] for article in all_data[name]['news']}
            new_articles = [a for a in articles if a['link'] not in existing_links]
            
            all_data[name]['news'].extend(new_articles)
            all_data[name]['total_count'] = len(all_data[name]['news'])
            all_data[name]['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            collected_count += len(new_articles)
            print(f"  ğŸ“° ì‹ ê·œ ê¸°ì‚¬: {len(new_articles)}ê±´ (ì „ì²´: {all_data[name]['total_count']}ê±´)")
        else:
            failed_count += 1
            print(f"  âŒ ìˆ˜ì§‘ ì‹¤íŒ¨")
        
        # API í˜¸ì¶œ ì œí•œ (ì´ˆë‹¹ 10ê±´) - 0.1ì´ˆ ëŒ€ê¸°
        time.sleep(0.1)
        
        # 10ëª…ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        if i % 10 == 0:
            save_data(all_data)
            print(f"\nğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ ({i}/{len(members)})")
    
    # ìµœì¢… ì €ì¥
    save_data(all_data)
    
    print("\n" + "="*60)
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì´ {collected_count}ê±´ì˜ ì‹ ê·œ ê¸°ì‚¬")
    if failed_count > 0:
        print(f"âš ï¸  ìˆ˜ì§‘ ì‹¤íŒ¨: {failed_count}ëª…")
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(all_data)}ëª…ì˜ êµ­íšŒì˜ì›, {sum(d['total_count'] for d in all_data.values())}ê±´ì˜ ê¸°ì‚¬")
    print(f"ğŸ• ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60 + "\n")


def schedule_daily_collection():
    """ë§¤ì¼ 3íšŒ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ ì„¤ì •"""
    # ë§¤ì¼ ì˜¤ì „ 9ì‹œ, ì˜¤í›„ 3ì‹œ, ì˜¤í›„ 9ì‹œì— ìˆ˜ì§‘
    schedule.every().day.at("09:00").do(collect_all_news)
    schedule.every().day.at("15:00").do(collect_all_news)
    schedule.every().day.at("21:00").do(collect_all_news)
    
    print("â° ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
    print("ğŸ“… ìˆ˜ì§‘ ì‹œê°„: ë§¤ì¼ 09:00, 15:00, 21:00")
    print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
    
    # ì²« ì‹¤í–‰
    collect_all_news()
    
    # ìŠ¤ì¼€ì¤„ ì‹¤í–‰
    while True:
        schedule.run_pending()
        time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--once":
        # 1íšŒë§Œ ì‹¤í–‰
        collect_all_news()
    elif len(sys.argv) > 1 and sys.argv[1] == "--schedule":
        # ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ì‹¤í–‰
        try:
            schedule_daily_collection()
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")
    else:
        print("ì‚¬ìš©ë²•:")
        print("  python collect_assembly_member_news.py --once      # 1íšŒ ì‹¤í–‰")
        print("  python collect_assembly_member_news.py --schedule  # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ (ë§¤ì¼ 3íšŒ)")

